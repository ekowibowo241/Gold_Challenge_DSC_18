{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e857a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in 'C:\\\\Users\\\\test\\\\Documents\\\\DATA SCIENCE BOOTCAMP\\\\DSC 18\\\\Challenge': ['.ipynb_checkpoints', 'abusive.csv', 'Archive', 'Archive.zip', 'citation.bib', 'data.csv', 'data.db', 'db_gold_challenge.db', 'docs', 'Eko_Wibowo_DSC18_gold_challenge.ipynb', 'Eko_Wibowo_DSC18_gold_challenge_final.ipynb', 'hello_world.yml', 'new_kamusalay.csv', 'text.yml', 'text_clean.yml', 'text_processing.yml', 'text_processing_file.yml']\n",
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import demoji\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from flask import Flask, jsonify\n",
    "from flask import request\n",
    "from flasgger import Swagger, LazyString, LazyJSONEncoder\n",
    "from flasgger import swag_from\n",
    "from flask import Flask, Response, jsonify\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "files = os.listdir(cwd)\n",
    "print(\"Files in %r: %s\" %(cwd, files))\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "#membaca file csv abusive dan kamus alay\n",
    "\n",
    "df_abusive = pd.read_csv('abusive.csv')\n",
    "df_alay = pd.read_csv('new_kamusalay.csv',encoding= 'latin-1')\n",
    "df_alay.columns = ['k_alay', 'k_baku']\n",
    "\n",
    "\n",
    "#mengeksport data abusive dan kamus alay ke database\n",
    "\n",
    "connection=sqlite3.connect('db_gold_challenge.db')\n",
    "cursorObj = connection.cursor()\n",
    "\n",
    "\n",
    "#menyimpan data hasil cleansing ke Database\n",
    "\n",
    "cursorObj.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS data_input (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        original_text TEXT,\n",
    "        clean_text TEXT\n",
    "    )\n",
    "''')\n",
    "connection.commit()\n",
    "\n",
    "#  FUnction cleansing\n",
    "\n",
    "def cleansing(sent):\n",
    "       \n",
    "    string = sent.lower()\n",
    "    string = re.sub(r'[^a-zA-Z0-9]',' ', string)\n",
    "    string = re.sub(r'http\\S+', '', string)  \n",
    "    string = re.sub(r'[^\\x00-\\x7f]',r'', string)\n",
    "    string = re.sub('\\?', '', string)\n",
    "    string = string.replace('/na', '')\n",
    "    string = re.sub(r'www\\.[^ ]+', '', string)\n",
    "    string = re.sub(r'[^a-zA-Z0-9\\s]', '', string)\n",
    "    string = re.sub(r'\\b(\\w+)\\b\\s+\\b\\1\\b', r'\\1', string)\n",
    "    string = re.sub(r'(\\w)(\\1{2,})', r\"\\1\", string)\n",
    "    string = re.sub(r\"\\b[a-zA-Z]\\b\",\"\",string)\n",
    "    string = re.sub('(s{2,})',' ',string)\n",
    "    string = demoji.replace(string, '')\n",
    "    string = string.strip()\n",
    "\n",
    "    characters_to_remove = ['xf0', 'x9f', 'x8f', 'xe2', 'x80', 'x9c', 'x84', 'xa3', 'x98', 'x86',\n",
    "                        'xc2', 'xb2', 'x9d', 'xa4', 'xa2', 'x99', 'xab', 'xaa', 'xe1',\n",
    "                        'xbd', 'xcf', 'xaa', 'xce', 'xb5', 'xcf', 'x81', 'xce', 'xb7',\n",
    "                        'xb1', 'xaf', 'xc4', 'x93', 'x82', 'xd', 'url','x8e', 'xb6', 'x8e', 'xa7', 'xa5', 'x8d', 'xba',\n",
    "                        'x91', 'x8c', 'x88', 'x94', 'x85', 'xa6', 'x91', 'xa', 'x92', 'x89', 'xad',\n",
    "                        'xb3', 'xd0', 'xbc', 'xd1', 'xc6', 'xd0', 'xbcs', 'xa6', 'x83', 'x9b',\n",
    "                        'xac', 'xef', 'xbc', 'xef', 'xa5', 'xe0', 'xb8', 'xb4', 'x8c', 'xef', 'xa5', 'xe0', 'xb8', 'xb4', 'xef', 'xbc']\n",
    "        \n",
    "    for char_sequence in characters_to_remove:\n",
    "        string = string.replace(char_sequence, '')\n",
    "        \n",
    "    string = re.sub(\"(username|user|url|rt|xf|fx|xe|xa)\\s|\\s(user|url|rt|xf|fx|xe|xa)\",\"\",string)\n",
    "        \n",
    "    return string\n",
    "\n",
    "\n",
    "# Function replace alay\n",
    "\n",
    "database_alay = dict(zip(df_alay['k_alay'], df_alay['k_baku']))\n",
    "\n",
    "def replace_alay(text, database_alay, compiled_alay_patterns):\n",
    "    for alay_pattern, baku_word in zip(compiled_alay_patterns, database_alay.values()):\n",
    "        text = alay_pattern.sub(baku_word, text)\n",
    "    return text\n",
    "\n",
    "compiled_alay_patterns = [re.compile(rf'\\b{re.escape(alay_word)}\\b', flags=re.IGNORECASE) for alay_word in database_alay.keys()]\n",
    "\n",
    "\n",
    "# Function Sensor Abusive\n",
    "\n",
    "database_kata_kasar = set(df_abusive['ABUSIVE'])\n",
    "\n",
    "def sensor_kalimat(teks, database_kata_kasar):\n",
    "    kata_kata = teks.split()\n",
    "    kata_kata_bersih = [kata if kata.lower() not in database_kata_kasar else '*' * len(kata) for kata in kata_kata]\n",
    "    kalimat_bersih = ' '.join(kata_kata_bersih)\n",
    "    return kalimat_bersih\n",
    "\n",
    "\n",
    "app.json_encoder = LazyJSONEncoder\n",
    "swagger_template = {\n",
    "    \"info\": {\n",
    "        \"title\":  \"API Documentation for Data Processing and Modeling\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"description\": \"Dokumentasi API untuk Data Processing dan Modeling Tugas Gold Challenge\"\n",
    "    },\n",
    "    \"host\": \"127.0.0.1:5000\"\n",
    "}\n",
    "\n",
    "swagger_config = {\n",
    "    \"headers\": [],\n",
    "    \"specs\": [\n",
    "        {\n",
    "            \"endpoint\": 'docs',\n",
    "            \"route\": '/docs.json',\n",
    "        }\n",
    "    ],\n",
    "    \"static_url_path\": \"/flasgger_static\",\n",
    "    \"swagger_ui\": True,\n",
    "    \"specs_route\": \"/docs/\"\n",
    "}\n",
    "\n",
    "\n",
    "swagger = Swagger(app, template=swagger_template,             \n",
    "                  config=swagger_config)\n",
    "\n",
    "@swag_from(\"/Users/test/Documents/DATA SCIENCE BOOTCAMP/DSC 18/Challenge/docs/hello_world.yml\", methods=['GET'])\n",
    "@app.route('/', methods=['GET'])\n",
    "def hello_world():\n",
    "    json_response = {\n",
    "        'status_code': 200,\n",
    "        'description': \"Menyapa Hello World\",\n",
    "        'data': \"Hello World\",\n",
    "    }\n",
    "\n",
    "    response_data = jsonify(json_response)\n",
    "    return response_data\n",
    "\n",
    "\n",
    "@swag_from(\"/Users/test/Documents/DATA SCIENCE BOOTCAMP/DSC 18/Challenge/docs/text_processing.yml\", methods=['POST'])\n",
    "@app.route('/text-processing', methods=['POST'])\n",
    "def text_processing():\n",
    "\n",
    "    \n",
    "    text = request.form.get('text')\n",
    "    \n",
    "    \n",
    "    # Menjalankan proses cleansing\n",
    "    \n",
    "    text_cleansing = cleansing(text)\n",
    "    \n",
    "    \n",
    "    # Menjalankan proses mengganti kata alay\n",
    "\n",
    "\n",
    "    text_cleansing_alay = replace_alay(text_cleansing, database_alay, compiled_alay_patterns)\n",
    "    \n",
    "    \n",
    "    # Menjalankan proses sensor kata abusive\n",
    "\n",
    "\n",
    "    text_cleansing_alay_sensor = sensor_kalimat(text_cleansing_alay, database_kata_kasar)\n",
    "\n",
    "    \n",
    "    # menyimpan hasil cleansing ke database \n",
    "    \n",
    "    entities = (text, text_cleansing_alay_sensor)\n",
    "    connection=sqlite3.connect('db_gold_challenge.db')\n",
    "    cursorObj = connection.cursor()\n",
    "    cursorObj.execute('''\n",
    "        INSERT INTO data_input (original_text, clean_text)\n",
    "        VALUES (?, ?)\n",
    "    ''', entities)\n",
    "    connection.commit()\n",
    "        \n",
    "    json_response = {\n",
    "        'status_code': 200,\n",
    "        'description': \"Teks yang sudah diproses cleansing dan sensor abusive\",\n",
    "        'data': text_cleansing_alay_sensor,\n",
    "    }\n",
    " \n",
    "    \n",
    "    response_data = jsonify(json_response)\n",
    "    \n",
    "#     connection.close()\n",
    "    \n",
    "    return response_data\n",
    "\n",
    "\n",
    "\n",
    "@swag_from(\"/Users/test/Documents/DATA SCIENCE BOOTCAMP/DSC 18/Challenge/docs/text_processing_file.yml\", methods=['POST'])\n",
    "@app.route('/text-processing-file', methods=['POST'])\n",
    "def text_processing_file():\n",
    "\n",
    "    # Upladed file\n",
    "    file = request.files.getlist('file')[0]\n",
    "\n",
    "    # Import file csv ke Pandas\n",
    "    df = pd.read_csv(file, encoding='latin1')\n",
    "    \n",
    "    #verifikasi data tweet apakah available \n",
    "    \n",
    "    if 'Tweet' not in df.columns:\n",
    "        raise ValueError('Column \"Tweet\" not found')\n",
    "        \n",
    "    # menghapus data yang duplicate\n",
    "#     df = df.drop_duplicates()\n",
    "\n",
    "\n",
    "    # Ambil teks yang akan diproses dalam format list\n",
    "    texts = df['Tweet'].to_list()\n",
    "\n",
    "    # Lakukan cleansing pada teks\n",
    "    \n",
    "    df['Tweet clean'] = df['Tweet'].apply(cleansing)\n",
    "    \n",
    "    \n",
    "    # Menjalankan proses mengganti kata alay\n",
    "\n",
    "    df['Tweet replace alay'] = df['Tweet clean'].apply(lambda tweet: replace_alay(tweet, database_alay, compiled_alay_patterns))\n",
    "\n",
    "    \n",
    "    # Menjalankan proses sensor kata abusive\n",
    "\n",
    "\n",
    "    df['Tweet sensor abusive'] = df['Tweet replace alay'].apply(lambda tweet: sensor_kalimat(tweet, database_kata_kasar))\n",
    "\n",
    "    \n",
    "    # menyimpan data ke database\n",
    "    connection=sqlite3.connect('db_gold_challenge.db')\n",
    "    cursorObj = connection.cursor()\n",
    "    kolom_yang_diekspor = ['Tweet', 'Tweet sensor abusive']\n",
    "    df_subset = df[kolom_yang_diekspor]\n",
    "    df_subset.to_sql(name='tb_data_file_ir', con=connection, index=False, if_exists='replace')\n",
    "   \n",
    "    # mengubah data ke json\n",
    "    \n",
    "    cursor = connection.execute(\"SELECT * FROM tb_data_file_ir\")\n",
    "    data = cursor.fetchall()\n",
    "    \n",
    "    json_data = []\n",
    "    for row in data:\n",
    "        json_data.append( row[1]) #urutan kolom data tweet yang telah dicleansing\n",
    "        \n",
    "    \n",
    "    json_response = {\n",
    "        'status_code': 200,\n",
    "        'description': \"File yang sudah diproses cleansing dan sensor abusive\",\n",
    "        'data': json_data,\n",
    "    }\n",
    "\n",
    "    response_data = jsonify(json_response)\n",
    "    \n",
    "#     connection.close()\n",
    "    \n",
    "    return response_data\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31eb2b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in 'C:\\\\Users\\\\test\\\\Documents\\\\DATA SCIENCE BOOTCAMP\\\\DSC 18\\\\Challenge': ['.ipynb_checkpoints', 'abusive.csv', 'Archive', 'Archive.zip', 'citation.bib', 'data.csv', 'data.db', 'db_gold_challenge.db', 'docs', 'docs.zip', 'Eko_Wibowo_DSC18_gold_challenge.ipynb', 'Eko_Wibowo_DSC18_gold_challenge_final.ipynb', 'new_kamusalay.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "files = os.listdir(cwd)\n",
    "print(\"Files in %r: %s\" %(cwd, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b121fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_alay = pd.read_csv('new_kamusalay.csv',encoding= 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e354c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anakjakartaasikasik</th>\n",
       "      <th>anak jakarta asyik asyik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pakcikdahtua</td>\n",
       "      <td>pak cik sudah tua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pakcikmudalagi</td>\n",
       "      <td>pak cik muda lagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3tapjokowi</td>\n",
       "      <td>tetap jokowi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3x</td>\n",
       "      <td>tiga kali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aamiin</td>\n",
       "      <td>amin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15161</th>\n",
       "      <td>mendikbud</td>\n",
       "      <td>menteri pendidikan dan kebudayaan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15162</th>\n",
       "      <td>mendag</td>\n",
       "      <td>menteri perdagangan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15163</th>\n",
       "      <td>menaker</td>\n",
       "      <td>menteri tenaga kerja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15164</th>\n",
       "      <td>memetwit</td>\n",
       "      <td>mentwit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15165</th>\n",
       "      <td>megangin</td>\n",
       "      <td>memegang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15166 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      anakjakartaasikasik           anak jakarta asyik asyik\n",
       "0            pakcikdahtua                  pak cik sudah tua\n",
       "1          pakcikmudalagi                  pak cik muda lagi\n",
       "2             t3tapjokowi                       tetap jokowi\n",
       "3                      3x                          tiga kali\n",
       "4                  aamiin                               amin\n",
       "...                   ...                                ...\n",
       "15161           mendikbud  menteri pendidikan dan kebudayaan\n",
       "15162              mendag                menteri perdagangan\n",
       "15163             menaker               menteri tenaga kerja\n",
       "15164            memetwit                            mentwit\n",
       "15165            megangin                           memegang\n",
       "\n",
       "[15166 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706c4278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
